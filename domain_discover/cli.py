"""Command-line interface for domain discovery pipeline."""

import argparse
import json
import os
from pathlib import Path
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

from wordnet_conditioner import WordNetConditioner
from diffusion import DiffusionTextGenerator
from blackbox import BlackBox
from pipeline import optimise_prompt_vector
from optimizer import optimize_x_start, calculate_diversity
from collections import OrderedDict
from generater import optimize_soft_prompt_dynamic, optimize_dimension
# Import DiffuSeq utilities
import sys

# ç¡®ä¿DiffuSeqåœ¨è·¯å¾„ä¸­
def setup_diffuseq_path():
    """ç¡®ä¿DiffuSeqè·¯å¾„æ­£ç¡®æ·»åŠ åˆ°sys.pathä¸­"""
    # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        Path(__file__).parent.parent / 'DiffuSeq',
        Path(__file__).parent.parent / 'DiffuSeq' / 'DiffuSeq',
        Path('/home/dora/Domain-Inference/DiffuSeq'),
        Path('/home/dora/Domain-Inference/DiffuSeq/DiffuSeq')
    ]
    
    for path in possible_paths:
        if (path / 'diffuseq').exists():
            path_str = str(path)
            if path_str not in sys.path:
                sys.path.insert(0, path_str)
            return True
            
    return False

# è®¾ç½®è·¯å¾„
if not setup_diffuseq_path():
    print("è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°DiffuSeqè·¯å¾„ï¼Œè¯·ç¡®ä¿DiffuSeqå·²æ­£ç¡®å®‰è£…")

# å¯¼å…¥DiffuSeqå·¥å…·
try:
    from basic_utils import add_dict_to_argparser, load_defaults_config
except ImportError:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥DiffuSeqå·¥å…·ï¼Œè¯·æ£€æŸ¥DiffuSeqå®‰è£…è·¯å¾„")
    
    # æä¾›ç®€å•çš„æ›¿ä»£å‡½æ•°ï¼Œä»¥é˜²å¯¼å…¥å¤±è´¥
    def add_dict_to_argparser(parser, default_dict):
        for k, v in default_dict.items():
            v_type = type(v)
            parser.add_argument(f"--{k}", default=v, type=v_type)
            
    def load_defaults_config():
        return {"hidden_dim": 128, "seq_len": 128}


def create_argparser():
    # åŸºç¡€å‚æ•°
    defaults = dict(
        model_path='/home/dora/Domain-Inference/model/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test_ori20221113-20:27:29',
        step=0,
        out_dir='output',
        top_p=0.9,
        target_label=0,
        eta=0.85,
        max_steps=8000,
        batch_size=1
    )
    
    # è§£ç ç‰¹å®šå‚æ•°
    decode_defaults = dict(
        split='valid',
        clamp_step=0,
        seed2=105,
        clip_denoised=True,
        use_ddim=True,
        ddim_steps=200,
        condition_len=5
    )
    
    # åŠ è½½DiffuSeqé»˜è®¤é…ç½®
    try:
        defaults.update(load_defaults_config())
    except Exception as e:
        print(f"Warning: Could not load DiffuSeq defaults: {e}")
    
    # æ›´æ–°è§£ç å‚æ•°
    defaults.update(decode_defaults)
    
    # åˆ›å»ºè§£æå™¨
    parser = argparse.ArgumentParser(description="Domain Discovery Pipeline")
    
    # æ·»åŠ å­è§£æå™¨
    add_dict_to_argparser(parser, defaults)
    
    # æ·»åŠ åŸºæœ¬å‚æ•°
    parser.batch_size = 1
    parser.add_argument(
        "--blackbox_model_name",
        type=str,
        # required=True,
        default="j-hartmann/emotion-english-distilroberta-base",
        help="HuggingFace model name for black-box classifier,s-nlp/roberta_toxicity_classifier,j-hartmann/emotion-english-distilroberta-base, nlptown/bert-base-multilingual-uncased-sentiment"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        # required=True,
        default='/home/dora/Domain-Inference/domain_discover/output',
        help="Directory to save results"
    )
    
    # æ·»åŠ x_startä¼˜åŒ–ç›¸å…³å‚æ•°
    parser.add_argument(
        "--optimize_x_start", 
        action="store_true",
        default=True,
        help="æ˜¯å¦ä¼˜åŒ–x_startä»¥æ»¡è¶³æˆåŠŸç‡å’Œå¤šæ ·æ€§è¦æ±‚"
    )
    parser.add_argument(
        "--target_success_rate", 
        type=float, 
        default=0.8,
        help="ç›®æ ‡æˆåŠŸç‡é˜ˆå€¼ï¼ŒèŒƒå›´[0,1]ï¼Œè¡¨ç¤ºblack_boxè¿”å›1çš„æ¯”ä¾‹"
    )
    parser.add_argument(
        "--diversity_weight", 
        type=float, 
        default=0.3,
        help="å¤šæ ·æ€§æƒé‡ï¼Œæ§åˆ¶ä¼˜åŒ–è¿‡ç¨‹ä¸­å¤šæ ·æ€§çš„é‡è¦ç¨‹åº¦"
    )
    parser.add_argument(
        "--max_iterations", 
        type=int, 
        default=50,
        help="x_startä¼˜åŒ–çš„æœ€å¤§è¿­ä»£æ¬¡æ•°"
    )
    parser.add_argument(
        "--learning_rate", 
        type=float, 
        default=0.01,
        help="x_startä¼˜åŒ–çš„å­¦ä¹ ç‡"
    )
    parser.add_argument(
        "--gradient_method", 
        type=str,
        choices=["finite_diff", "random", "diversity", "batch"],
        default="nes_prior",
        help="æ¢¯åº¦ä¼°è®¡æ–¹æ³•: finite_diff(æœ‰é™å·®åˆ†æ³•), random(éšæœºåæ ‡ä¸‹é™), diversity(è€ƒè™‘å¤šæ ·æ€§), batch(æ‰¹å¤„ç†)"
    )
    parser.add_argument(
        "--num_samples", 
        type=int, 
        default=10,
        help="æ¯æ¬¡è¯„ä¼°ç”Ÿæˆçš„æ ·æœ¬æ•°é‡"
    )
    return parser


def sample_seq2seq_command(args):
    """å¤„ç† seq2seq é‡‡æ ·å­å‘½ä»¤"""
    from seq2seq_sampler import sample_seq2seq
    output_path = sample_seq2seq(args)
    print(f"é‡‡æ ·å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {output_path}")

def run_domain_discovery(args):
    """è¿è¡ŒåŸŸå‘ç°ç®¡é“"""
    # Setup device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # Create output directory
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Initialize components
    generator = DiffusionTextGenerator(
        model_path=args.model_path,
        device=device,
        use_ddim=args.use_ddim,
        clip_denoised=args.clip_denoised,
        ddim_steps=args.ddim_steps,
        top_p=args.top_p,
        clamp_step=args.clamp_step,
        batch_size=args.batch_size,
        seq_len=args.seq_len if hasattr(args, 'seq_len') else 128,
        split=args.split,
        output_dir=args.output_dir,
        world_size=1,
        rank=0
    )
    
    black_box = BlackBox(model_name=args.blackbox_model_name)
    
    # è·å–æ¨¡å‹çš„hidden_dim
    hidden_dim = generator.config.get("hidden_dim", 128)
    print(f"Using hidden_dim: {hidden_dim}")
    
    wordnet_conditioner = WordNetConditioner(hidden_dim=hidden_dim, init_method='wordnet', black_model=black_box, max_words=5000, min_words_per_category=20, load_from_wordnet=True).to(device)
    sorted_embeddings_words_dict = OrderedDict(sorted(wordnet_conditioner.embeddings_words_dict.items(), key=lambda x: int(x[0])))

    for label, words in sorted_embeddings_words_dict.items():
        print(f"\nğŸ”º Generating for label: {label+1} from wordnet: {words}")
        # sorted_embeddings_words_dict[label] = words
        z, pca, valid_words = optimize_dimension(label, words, black_box)
        best_z, samples = optimize_soft_prompt_dynamic(
            target_label   = label,
            black_box      = black_box,          # ä½ çš„åˆ†ç±»å™¨
            prefix_len     = 8,
            initial_words  = words,          # â† æ–°å¢å…¥å£
            # prompt_text    = " Please write a short English sentence:",
            sigma0         = 0.04,
            iterations     = 25,
            samples_per_eval = 15,
            temperature    = 0.7,
            top_p          = 0.8,
            mu             = 0.0,
        )
    # ç”Ÿæˆç¤ºä¾‹æ–‡æœ¬
    for label, words in sorted_embeddings_words_dict.items():
        print(f"\nğŸ”º Generating for label: {label+1} from wordnet: {words}")
        args.target_label = label
        conditioner = words[0]  # åªç”¨ç¬¬ä¸€ä¸ªè¯
        data_valid = generator._load_data_text(conditioner)
        cond = next(data_valid)[1]

        input_ids_x = cond['input_ids'].to(generator.device)  # shape: (1, L)
        input_ids_mask = cond['input_mask'].to(generator.device)  # shape: (1, L)

        x_start = generator.model.get_embeds(input_ids_x)  # shape: (1, L, D)

        # ç”Ÿæˆåˆå§‹æ ·æœ¬
        initial_samples = generator.generate_from_conditioner(x_start, input_ids_x, input_ids_mask, num_samples=args.num_samples)
        print("\nåˆå§‹æ ·æœ¬:")
        for i, t in enumerate(initial_samples):
            print(f"[Sample {i+1}]: {t}")
        
        # è¯„ä¼°åˆå§‹æ ·æœ¬
        initial_labels = black_box.predict(initial_samples)
        initial_success_rate = sum(initial_label == args.target_label for initial_label in initial_labels) / len(initial_labels)
        initial_diversity = calculate_diversity(initial_samples)
        print(f"åˆå§‹æˆåŠŸç‡: {initial_success_rate:.4f}, åˆå§‹å¤šæ ·æ€§: {initial_diversity:.4f}")
        
        # å¦‚æœå¯ç”¨äº†x_startä¼˜åŒ–
        if args.optimize_x_start:
            print("\nå¼€å§‹ä¼˜åŒ–x_start...")
            
            # ä¼˜åŒ–x_start
            optimized_x_start = optimize_x_start(
                initial_x_start=x_start,
                black_box=black_box,
                generator=generator,
                input_ids=input_ids_x,
                input_mask=input_ids_mask,
                num_samples=args.num_samples,
                target_label=args.target_label,
                eta=args.target_success_rate,
                max_iterations=args.max_iterations,
                learning_rate=args.learning_rate,
                diversity_weight=args.diversity_weight,
                gradient_method=args.gradient_method,
                verbose=True
            )
            
            # ä½¿ç”¨ä¼˜åŒ–åçš„x_startç”Ÿæˆæ ·æœ¬
            optimized_samples = generator.generate_from_conditioner(
                optimized_x_start, input_ids, input_mask, num_samples=10
            )
            
            # è¯„ä¼°ä¼˜åŒ–åçš„æ ·æœ¬
            optimized_labels = black_box.predict(optimized_samples)
            optimized_success_rate = sum(label==target_label for label in optimized_labels) / len(optimized_labels)
            optimized_diversity = calculate_diversity(optimized_samples)
            
            print("\nä¼˜åŒ–åçš„æ ·æœ¬:")
            for i, (sample, label) in enumerate(zip(optimized_samples, optimized_labels)):
                print(f"[Sample {i+1}] {'âœ“' if label == 1 else 'âœ—'}: {sample}")
        
        print(f"\nä¼˜åŒ–ç»“æœç»Ÿè®¡:")
        print(f"- åˆå§‹æˆåŠŸç‡: {initial_success_rate:.4f} -> ä¼˜åŒ–åæˆåŠŸç‡: {optimized_success_rate:.4f}")
        print(f"- åˆå§‹å¤šæ ·æ€§: {initial_diversity:.4f} -> ä¼˜åŒ–åå¤šæ ·æ€§: {optimized_diversity:.4f}")
        
        # ä¿å­˜ä¼˜åŒ–ç»“æœ
        results_path = output_dir / "optimization_results.json"
        results = {
            "initial_success_rate": float(initial_success_rate),
            "initial_diversity": float(initial_diversity),
            "optimized_success_rate": float(optimized_success_rate),
            "optimized_diversity": float(optimized_diversity),
            "initial_samples": initial_samples,
            "initial_labels": initial_labels,
            "optimized_samples": optimized_samples,
            "optimized_labels": optimized_labels,
            "optimization_params": {
                "target_success_rate": args.target_success_rate,
                "diversity_weight": args.diversity_weight,
                "max_iterations": args.max_iterations,
                "learning_rate": args.learning_rate,
                "gradient_method": args.gradient_method,
                "num_samples": args.num_samples
            }
        }
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    # è¿è¡ŒåŸæœ‰çš„ä¼˜åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.max_steps > 0 and 'wordnet_conditioner' in locals():
        print("\nStarting prompt vector optimization...")
        optimise_prompt_vector(
            generator=generator,
            bb=black_box,
            prompt_vec=wordnet_conditioner,
            target_label=args.target_label,
            eta=args.target_success_rate,
            max_steps=args.max_steps,
            batch_size=args.batch_size,
            output_dir=output_dir
        )
        print(f"\nOptimization complete. Results saved to: {output_dir}")


def main():
    parser = create_argparser()
    args = parser.parse_args()
    
    # æ ¹æ®å­å‘½ä»¤æ‰§è¡Œç›¸åº”çš„åŠŸèƒ½
    if hasattr(args, 'command') and args.command == "seq2seq":
        sample_seq2seq_command(args)
    else:
        # é»˜è®¤è¿è¡ŒåŸŸå‘ç°ç®¡é“
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå‘½ä»¤æˆ–å‘½ä»¤æ˜¯"run"
        run_domain_discovery(args)


if __name__ == "__main__":
    main()
