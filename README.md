# Domain-Inference

This project aims to discover knowledge domain features corresponding to each label in language classification models. It works by obtaining embeddings containing label-specific knowledge, guiding language generation models to produce texts corresponding to the target label, and using large language models for concept extraction.

## ğŸ“ Project Structure

```bash
domain-inference/
â”œâ”€â”€ scripts/                      # Script entry points
â”‚   â”œâ”€â”€ optimize_embedding.py     # Embedding optimization 
â”‚   â”œâ”€â”€ prefix_tuning_T5.py       # T5 model prefix tuning 
â”‚   â””â”€â”€ run.sh                    # Main execution script
â”œâ”€â”€ src/                          # Source code
â”‚   â””â”€â”€ domain_infer/             # Main application logic
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ classifier.py           # Blackbox classifier evaluation
â”‚       â”œâ”€â”€ generater.py          # Text generator
â”‚       â”œâ”€â”€ optimizer.py          # Soft prompt optimizer
â”‚       â”œâ”€â”€ wordnet_init.py       # WordNet conditioner
â”œâ”€â”€ data/                         # Data directory
â”‚   â””â”€â”€ init_from_wordnet
â”‚       â”œâ”€â”€ init_from_bert 
â””â”€â”€ models/                       # Pretrained or fine-tuned models
â”‚   â””â”€â”€ bert
â”œâ”€â”€ README.md                     # Project overview
â”œâ”€â”€ pyproject.toml                # Project metadata and dependencies
â”œâ”€â”€ uv.lock                       # Locked dependencies (used by uv)
```

## Installation
We use [uv](https://docs.astral.sh/uv/) to manage Python dependencies. See the [uv installation instructions](https://docs.astral.sh/uv/getting-started/installation/) to set it up. Once uv is installed, run the following to set up the environment:

```bash
uv sync
uv pip install -e .
```

# Usage